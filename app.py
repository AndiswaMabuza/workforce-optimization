import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from prophet import Prophet
from sklearn.metrics import mean_absolute_error, mean_squared_error

# --- Title ---
st.title("ğŸ“Š AI-Driven Resource Planning & Workforce Optimization for a Multilingual Contact Center")

@st.cache_data
def simulate_contact_volume():
    regions = ["South Africa", "Nigeria", "Morocco", "Kenya", "UK"]
    channels = ["Call", "Email", "Chat"]
    languages = ["English", "French", "Arabic", "Swahili", "Zulu"]
    ts_range = pd.date_range("2025-01-01", "2025-01-14 23:45", freq="15T")

    rows = []
    for ts in ts_range:
        for ch in channels:
            for lang in languages:
                for reg in regions:
                    base = np.random.poisson(2 if ch == "Email" else 4)
                    volume = max(0, int(base + 3*np.sin(ts.hour/24*np.pi) + np.random.normal()))
                    rows.append([ts, ch, lang, reg, volume])
    return pd.DataFrame(rows, columns=["timestamp", "channel", "language", "region", "contact_volume"])

contact_df = simulate_contact_volume()

channel = st.selectbox("Select Channel to Forecast", ["Call", "Email", "Chat"])

channel_df = contact_df[contact_df["channel"] == channel]
agg = channel_df.groupby("timestamp")["contact_volume"].sum().reset_index()
agg.columns = ["ds", "y"]

model = Prophet(daily_seasonality=True, weekly_seasonality=True)
model.fit(agg)
future = model.make_future_dataframe(periods=96*3, freq="15min")
forecast = model.predict(future)

merged = pd.merge(agg, forecast[["ds", "yhat"]], on="ds")
mae = mean_absolute_error(merged["y"], merged["yhat"])
mape = np.mean(np.abs((merged["y"] - merged["yhat"]) / merged["y"])) * 100
rmse = np.sqrt(mean_squared_error(merged["y"], merged["yhat"]))

st.subheader(f"ğŸ“ˆ Forecast for {channel} Volume")
fig = px.line(forecast, x="ds", y="yhat", title="Forecasted Contact Volume")
st.plotly_chart(fig)

st.markdown("### âœ… Forecast Accuracy Metrics")
st.metric("MAE", f"{mae:.2f}")
st.metric("MAPE", f"{mape:.2f}%")
st.metric("RMSE", f"{rmse:.2f}")

@st.cache_data
def generate_schedule():
    agents = [f"A{i:03}" for i in range(1, 101)]
    shifts = ["08:00-16:00", "09:00-17:00", "12:00-20:00", "14:00-22:00"]
    sched = []
    for agent in agents:
        for d in pd.date_range("2025-01-01", "2025-01-14"):
            shift = np.random.choice(shifts)
            sched.append([agent, d.date(), shift])
    return pd.DataFrame(sched, columns=["agent_id", "date", "shift"])

st.subheader("ğŸ“… Shift Schedule Heatmap")
schedule_df = generate_schedule()
heatmap_df = schedule_df.groupby(["date", "shift"]).size().unstack().fillna(0)

fig2 = px.imshow(heatmap_df.T, aspect="auto", labels=dict(x="Date", y="Shift", color="Agent Count"))
st.plotly_chart(fig2)

st.subheader("ğŸš¨ Scenario Simulation: Mid-Day Spike")
sim_df = forecast.copy()
sim_df["yhat_spike"] = sim_df["yhat"]
sim_df.loc[sim_df["ds"].dt.hour.between(10, 14), "yhat_spike"] *= 1.5

fig3 = px.line(sim_df, x="ds", y=["yhat", "yhat_spike"], labels={"value": "Contact Volume"}, title="Spike vs Normal Forecast")
st.plotly_chart(fig3)

st.subheader("ğŸ§¾ Executive Summary")
st.markdown("""
- ğŸ“ Call volume peaks midday across all regions.
- ğŸ‘· FTE needs increase ~30% during 10amâ€“2pm.
- ğŸ“Ÿ Shift coverage is unevenâ€”optimize staggered shifts.
- âš ï¸ Real-time dashboards can boost SLA compliance.
- ğŸ§  Simulations allow smarter peak-time planning.
""")
